{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Setup autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Give yourself access to common\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather training and testing data and process it to be configured for time intervals\n",
    "from common import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "nba = get_cleaned_external_data(next_year_salary=True)\n",
    "# nba = get_cleaned_baseline_data(next_year_salary=True)\n",
    "FUT_SAL_CLASS = 'future_salary_class'\n",
    "max = nba[NEXT_Y_SAL].max()\n",
    "min = nba[NEXT_Y_SAL].min()\n",
    "nba[FUT_SAL_CLASS] = nba[NEXT_Y_SAL].apply(lambda x: get_salary_class(x,max,min))\n",
    "\n",
    "for i, row in nba.iterrows() :\n",
    "    next_val = nba.loc[((nba[P_NAME] == row[P_NAME]) & (nba[SZN_START_Y] == (row[SZN_START_Y]+1)))]  \n",
    "    if not next_val.empty :\n",
    "        nba.loc[i,'y'] = next_val.index[0]\n",
    "    else :\n",
    "        nba.loc[i,'y'] = np.nan\n",
    "nba = nba.drop(P_NAME, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['seasonStartYear', 'MP', 'PTS', 'Age', 'games', 'games_started', 'PER',\n",
      "       'FTr', 'AST', 'STL', 'TRB', 'FT', '3P', 'FG', 'height', 'weight',\n",
      "       'inflationAdjSalary', 'startYear', 'all_star_total', 'all_star_enc',\n",
      "       'all_nba_enc', 'all_nba_total', 'draft_pick', 'champion',\n",
      "       'conference_champ', 'mvp', 'mvp_rank', 'mvp_total', 'player_week_enc',\n",
      "       'player_week_total', 'dpoy', 'dpoy_rank', 'dpoy_total',\n",
      "       'next_year_salary', 'future_salary_class', 'y'],\n",
      "      dtype='object')\n",
      "['MP', 'PTS', 'Age', 'games', 'games_started', 'PER', 'FTr', 'AST', 'STL', 'TRB', 'FT', '3P', 'FG', 'height', 'weight', 'inflationAdjSalary', 'startYear', 'all_star_total', 'all_star_enc', 'all_nba_enc', 'all_nba_total', 'draft_pick', 'champion', 'conference_champ', 'mvp', 'mvp_rank', 'mvp_total', 'player_week_enc', 'player_week_total', 'dpoy', 'dpoy_rank', 'dpoy_total', 'future_salary_class']\n",
      "['MP', 'PTS', 'Age', 'games', 'games_started', 'PER', 'FTr', 'AST', 'STL', 'TRB', 'FT', '3P', 'FG', 'height', 'weight']\n",
      "Index(['MP', 'PTS', 'Age', 'games', 'games_started', 'PER', 'FTr', 'AST',\n",
      "       'STL', 'TRB', 'FT', '3P', 'FG', 'height', 'weight',\n",
      "       'inflationAdjSalary', 'startYear', 'all_star_total', 'all_star_enc',\n",
      "       'all_nba_enc', 'all_nba_total', 'draft_pick', 'champion',\n",
      "       'conference_champ', 'mvp', 'mvp_rank', 'mvp_total', 'player_week_enc',\n",
      "       'player_week_total', 'dpoy', 'dpoy_rank', 'dpoy_total',\n",
      "       'future_salary_class'],\n",
      "      dtype='object')\n",
      "Index(['MP', 'PTS', 'Age', 'games', 'games_started', 'PER', 'FTr', 'AST',\n",
      "       'STL', 'TRB', 'FT', '3P', 'FG', 'height', 'weight',\n",
      "       'inflationAdjSalary', 'startYear', 'all_star_total', 'all_star_enc',\n",
      "       'all_nba_enc', 'all_nba_total', 'draft_pick', 'champion',\n",
      "       'conference_champ', 'mvp', 'mvp_rank', 'mvp_total', 'player_week_enc',\n",
      "       'player_week_total', 'dpoy', 'dpoy_rank', 'dpoy_total',\n",
      "       'future_salary_class'],\n",
      "      dtype='object')\n",
      "655.0\n",
      "2.228594445658938\n",
      "655.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize the data\n",
    "print(nba.columns)\n",
    "# print(y.columns)\n",
    "feats = nba.columns[1:-3]\n",
    "feats = list(feats)\n",
    "feats = feats + [FUT_SAL_CLASS]\n",
    "base_feats = feats[:15]\n",
    "print(feats)\n",
    "print(base_feats)\n",
    "\n",
    "X = pd.DataFrame(columns=feats)\n",
    "y = pd.DataFrame()\n",
    "X = nba.copy(deep=True)\n",
    "X = X.dropna()\n",
    "y = nba.loc[X['y']]\n",
    "\n",
    "X = X[feats]\n",
    "y = y[feats]\n",
    "print(X.columns)\n",
    "print(y.columns)\n",
    "# Scale the stuff down\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "y_scaled = scaler.transform(y)\n",
    "y_scaled = y_scaled[:,:(len(base_feats))]\n",
    "\n",
    "# Sanity check the scaler\n",
    "print((X['FG']).iloc[0])\n",
    "print(X_scaled[0, X.columns.get_loc('FG')])\n",
    "inv = scaler.inverse_transform(X_scaled)\n",
    "print(inv[0, X.columns.get_loc('FG')])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared value:  0.5873836306017871\n",
      "RMSE:  0.6642599502133956\n",
      "MSE: 0.4412412814575028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.8784,  0.5664,  1.503 , ...,  0.5788,  1.6408,  0.7872],\n",
       "       [ 0.8065,  0.8959,  1.2436, ...,  0.9473,  0.8153,  0.1395],\n",
       "       [ 0.3332,  0.2244,  0.7249, ...,  0.3237, -0.5605,  0.1036],\n",
       "       ...,\n",
       "       [ 0.0577, -0.0595, -0.3124, ..., -0.0505, -0.5605, -0.2203],\n",
       "       [ 0.6994,  0.8628, -0.5718, ...,  0.9643, -1.3859, -0.4721],\n",
       "       [ 0.4734,  0.2058,  0.7249, ...,  0.1423, -0.0101, -0.2203]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit the model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "\n",
    "# MLPClassifier only classifies data as integers or strings, therefore, our problem is one of regression for the neural network\n",
    "# Consequently I should use the mlp regressor\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10,10), solver='adam', max_iter=1000)\n",
    "mlp.fit(X_train,y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predict_test = mlp.predict(X_test)\n",
    "test_set_rsquared = mlp.score(X_test, y_test)\n",
    "test_set_rmse = np.sqrt(mean_squared_error(predict_test, y_test))\n",
    "test_set_mse = mean_squared_error(predict_test, y_test)\n",
    "print('R_squared value: ', test_set_rsquared) # Variances are not nicely correlated\n",
    "print('RMSE: ', test_set_rmse) # Fairly good at data prediction\n",
    "print('MSE:', test_set_mse)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "[[ 0.4264  0.5784  2.3788  0.0505  0.5925  1.0153  0.3534 -0.7917 -0.7157\n",
      "   1.5718  0.6989 -1.4203  0.7618  0.7093  0.9199]]\n",
      "[[ 0.4264  0.5784  2.3788  0.0505  0.5925  1.0153  0.3534 -0.7917 -0.7157\n",
      "   1.5718  0.6989 -1.4203  0.7618  0.7093  0.9199  0.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.    ]]\n",
      "[2036.1518477598797, 979.7887623317082, 35.3768650673631, 64.30965036949182, 55.01606902170512, 19.244233480165775, 0.3787563319716244, 35.64965898912267, 27.596594305369713, 616.5504944123429, 217.67925874612945, -30.42253766722962, 396.28501690611483]\n",
      "MP               848.000\n",
      "PTS              540.000\n",
      "Age               35.000\n",
      "games             26.000\n",
      "games_started     26.000\n",
      "PER               23.300\n",
      "FTr                0.462\n",
      "AST               28.000\n",
      "STL               16.000\n",
      "TRB              265.000\n",
      "FT               134.000\n",
      "3P                 0.000\n",
      "FG               203.000\n",
      "height            84.000\n",
      "weight           240.000\n",
      "Name: 444, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Denormalize the data\n",
    "predict_test = mlp.predict((X_scaled[0]).reshape(1,-1))\n",
    "print(X_train.shape[1])\n",
    "print(predict_test)\n",
    "tmp = np.zeros((1,X_train.shape[1]))\n",
    "tmp[:,:predict_test.shape[1]] = predict_test\n",
    "print(tmp)\n",
    "undone = scaler.inverse_transform(tmp)\n",
    "print(undone.flatten().tolist()[:13])\n",
    "print(y[base_feats].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Off by at most this much: [1162.6010485438574, 564.5294819959297, 0.9358547475622839, 36.678941065626624, 44.77237141825249, 5.681788518771645, 0.20083569593628162, 176.79757130821858, 50.42570265081218, 279.9271334943758, 140.38598344515225, 67.25290821346142, 211.85565399097388, 2.097975557900953, 17.64002385748879]\n",
      "[3485.  2832.    40.    85.    83.    45.3    6.   925.   225.  1226.\n",
      "  756.   402.   978.    90.   325. ]\n",
      "[  1.    0.   19.    1.    0.  -40.7   0.    0.    0.    0.    0.    0.\n",
      "   0.   63.  135. ]\n",
      "[[476.1579 496.692 ]\n",
      " [212.2525 222.3542]\n",
      " [  0.3576   0.3772]\n",
      " [ 13.7566  14.3724]\n",
      " [ 18.2243  18.9838]\n",
      " [  2.1591   2.2802]\n",
      " [  0.072    0.0783]\n",
      " [ 56.3487  59.6562]\n",
      " [ 18.633   19.5375]\n",
      " [ 99.8705 104.9828]\n",
      " [ 48.5911  51.2492]\n",
      " [ 21.9521  23.1666]\n",
      " [ 80.2483  84.0312]\n",
      " [  0.7928   0.831 ]\n",
      " [  7.0573   7.3689]]\n",
      "{'column_0': (475.79476645622674, 496.67383016962964), 'column_1': (212.41596990296983, 222.70172029234558), 'column_2': (0.35803130884824563, 0.3767257665685465), 'column_3': (13.760876366711393, 14.350450541466435), 'column_4': (18.25985083662169, 18.982653714292923), 'column_5': (2.16194368301781, 2.276515886020327), 'column_6': (0.07228690505247085, 0.07850881653611261), 'column_7': (56.42384431825786, 59.63269751811651), 'column_8': (18.637464708414942, 19.531274031203957), 'column_9': (100.04943013258044, 104.85566868220226), 'column_10': (48.65462707647754, 51.32500366985124), 'column_11': (21.997164469282435, 23.158852957745914), 'column_12': (80.12407636296908, 84.01731300550834), 'column_13': (0.7917827239438554, 0.8306204099297747), 'column_14': (7.057568917333044, 7.352953130176186)}\n",
      "HELLO\n",
      "[1017.7252  451.7522    0.6491   36.6789   35.6219    4.6071    0.1387\n",
      "  121.1894   36.891   215.9959   96.3966   42.129   167.0021    1.6828\n",
      "   13.9798]\n"
     ]
    }
   ],
   "source": [
    "# Compute the confidence interval of each of the features\n",
    "from common import *\n",
    "\n",
    "# Get the unscaled predictions\n",
    "predict_full = mlp.predict(X_scaled)\n",
    "tmp = np.zeros(X_scaled.shape)\n",
    "tmp[:,:predict_full.shape[1]] = predict_full\n",
    "predicted_unscaled_vals = scaler.inverse_transform(tmp)\n",
    "predicted_unscaled_vals = predicted_unscaled_vals[:,:predict_full.shape[1]]\n",
    "\n",
    "# compute the RMSE for each feature in the output vector\n",
    "actual_unscaled_vals = y[base_feats].values\n",
    "rmse = np.sqrt(np.square(predicted_unscaled_vals - actual_unscaled_vals))\n",
    "\n",
    "# compute the percentilse of the RMSE to get the confidence interval of each predicted feature\n",
    "ci_up = np.percentile(rmse, 95, axis=0) # 95th percentile\n",
    "ci_low = np.percentile(rmse, 5, axis=0) # 5th percentile\n",
    "print(\"Off by at most this much:\", ci_up.flatten().tolist())\n",
    "print(np.max(actual_unscaled_vals, axis=0))\n",
    "print(np.min(actual_unscaled_vals, axis=0)) \n",
    "# print(ci_low.flatten().tolist()) \n",
    "\n",
    "# TODO: validate these findings with the very basic network to see if it predicts that these stats will land us in our desired class\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "print(confidence_interval_numpy(predicted_unscaled_vals, actual_unscaled_vals)) # requires the assumption of gaussianity, but seems to be working?\n",
    "\n",
    "\n",
    "print(bootstrap_confidence_interval(predicted_unscaled_vals, actual_unscaled_vals)) # should be able to work without the assumption of gaussianity\n",
    "# computing for rmse, so says that the true root mean squared error has a 95% of landing in these intervals\n",
    "# residuals are likely far smaller because you have the negatives balancing things out so it is going to be less accurate for computing the confidence interval\n",
    "\n",
    "residuals = predicted_unscaled_vals - actual_unscaled_vals\n",
    "ci = np.quantile(residuals, 1 - 0.05, axis=0)\n",
    "print(\"HELLO\")\n",
    "print(ci)\n",
    "\n",
    "# I want to say that my prediction is between these 2 bounds with 95% confidence\n",
    "# The two functions I provided seem to find the rmse of each parameter with 95% confidence\n",
    "# the first and 4th method I try do not scale the mean of the data and therefore, I don't think they necessarily apply to giving me the confidence interval I desire\n",
    "\n",
    "\n",
    "\n",
    "# DO A CASE STUDY on an individual\n",
    "# ANALYZE THIS MODEL ON BASELINE AND EXTERNAL\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor \n",
    "# random_forest_model = RandomForestRegressor(n_estimators = 60, random_state = 0)\n",
    "\n",
    "# random_forest_model.fit(X_train, y_train) \n",
    "\n",
    "# y_pred = random_forest_model.predict(X_test)\n",
    "\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "# print(\"MSE: \",mse)\n",
    "# print(\"RMSE: \",rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
